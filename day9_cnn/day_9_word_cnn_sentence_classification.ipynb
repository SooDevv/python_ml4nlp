{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "이제 앞서 만들어둔 word vector 를 이용하여 Yoon Kim, 2015 의 word - level CNN sentence classifier 를 만들어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279677\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "from navermovie_comments import load_comments_image\n",
    "\n",
    "class CommentsImage(Dataset):\n",
    "    def __init__(self, large=False, max_len=20):\n",
    "        super(CommentsImage, self).__init__()\n",
    "        # use only this tokenizer\n",
    "        tokenize = 'soynlp_unsup'\n",
    "\n",
    "        self.X, labels, self.idx_to_vocab = load_comments_image(\n",
    "            large=large, tokenize=tokenize, max_len=max_len)\n",
    "\n",
    "        # {0: negative, 1: neutral, 2: positive}\n",
    "        labels[np.where(labels <= 4)[0]] = 0\n",
    "        labels[np.where((labels > 4) & (labels < 8))] = 1\n",
    "        labels[np.where(8 <= labels)[0]] = 2\n",
    "        self.labels = labels\n",
    "\n",
    "        # transform numpy.ndarray to torch.tensor\n",
    "        self.X = torch.LongTensor(self.X)\n",
    "        self.labels = torch.LongTensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.labels[index]\n",
    "        return X, y\n",
    "\n",
    "\n",
    "large = True\n",
    "data_name = 'large' if large else 'small'\n",
    "comments_images = CommentsImage(large)\n",
    "\n",
    "print(len(comments_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17358,   149,    83,   324, 93234, 93234, 93234, 93234, 93234, 93234,\n",
      "        93234, 93234, 93234, 93234, 93234, 93234, 93234, 93234, 93234, 93234])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "X, y = comments_images[2]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 학습한 word2vec model 에서 word vectors 도 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93234, 100)\n",
      "93235\n"
     ]
    }
   ],
   "source": [
    "from navermovie_comments import load_trained_embedding\n",
    "\n",
    "word2vec_model = load_trained_embedding(data_name=data_name,\n",
    "    tokenize='soynlp_unsup', embedding='word2vec')\n",
    "\n",
    "wv = word2vec_model.wv.vectors\n",
    "\n",
    "print(wv.shape)\n",
    "print(len(comments_images.idx_to_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding 을 위한 zero vectors 를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93235, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_vector = np.zeros((1, wv.shape[1]), dtype=wv.dtype)\n",
    "wv = np.vstack([wv, zero_vector])\n",
    "wv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 parameter 몇 가지를 미리 정의합니다. \n",
    "\n",
    "Yoon Kim (2015) 의 논문에서는 각 크기의 kernel 마다 100 개의 CNN filter 를 만들었습니다. 이를 num_filters 에 저장해둡니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data related parameter\n",
    "num_words, embedding_dim = wv.shape\n",
    "num_filters = 100\n",
    "num_classes = np.unique(comments_images.labels.numpy()).shape[0]\n",
    "n_data = len(comments_images)\n",
    "\n",
    "# training related parameter\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader 를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "use_cuda = False\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    comments_images, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## static CNN\n",
    "\n",
    "이번 예시는 아래의 reference 를 참고하였습니다. 유명한 모델들은 좋은 구현체들이 많습니다. 검색한 뒤, 본인의 스타일에 잘 맞는 코드를 이용하시면 좋습니다.\n",
    "\n",
    "reference : https://github.com/castorini/Castor/tree/master/kim_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model 역시 torch.nn.Module 을 상속할 것입니다. 기본 구조는 아래와 같습니다. init 과 forward 함수를 구현합니다. Python 에서 객체를 상속할 때에는 super().\\_\\_init\\_\\_ 을 반드시 구현해야 합니다.\n",
    "\n",
    "    class TextCNN(nn.Module):\n",
    "        def __init__(self, parameters ... ):\n",
    "            super(TextCNN, self).__init__()\n",
    "            # TODO\n",
    "\n",
    "        def forward(self, x):\n",
    "            # TODO\n",
    "\n",
    "우리는 static, non-static word - level sentence classifier 를 구현할 것입니다. 이들의 차이는 pre-trained word vector 를 이용하여 Embedding layer 를 초기화 한 뒤, static 은 word vector 를 학습하지 않으며, non-static 은 초기화된 word vector 에 classification 에 적합하도록 벡터를 변환하는 것입니다. static / non-static 은 TextCNN 를 만든 뒤, weight update 부분을 고정하는 것만 바꾸면 됩니다. multi-channels 는 torch.nn.Embedding 를 두 개 두고 하나의 word vector 를 고정하기만 하면 됩니다. Sentence classifier 를 구현하기 위하여 가장 간단한 모델부터 만들어봅니다.\n",
    "\n",
    "### init 함수 구현\n",
    "\n",
    "init 에는 단어의 임베딩 벡터 차원의 크기, 단어 개수, 필터 개수, 클래스 개수를 각각 입력받습니다. 이들은 CNN 과 fully connected layer 의 input - output dimension 을 정의하는데 필요합니다. pretrained_wordvec 은 gensim 으로 학습한 word vector 를 입력받는 부분입니다. Dropout-ratio 는 dropout 하는 units 의 비율입니다. \n",
    "\n",
    "입력된 embedding_dim 과 num_words 가 pretrained word vector 의 크기와 같은지 확인하는 부분을 추가하였습니다.\n",
    "\n",
    "    n, m = pretrained_wordvec.shape\n",
    "    assert n == num_words and m == embedding_dim\n",
    "\n",
    "일단 Embedding 을 이용하여 CNN 이 이용하는 단어 벡터를 만듭니다.\n",
    "\n",
    "    self.embed = nn.Embedding(num_words, embedding_dim)\n",
    "\n",
    "그리고 미리 학습된 word vector 의 값을 self.embed 에 복사합니다.\n",
    "\n",
    "    self.embed.weight.data.copy_(torch.from_numpy(pretrained_wordvec))\n",
    "\n",
    "Yoon Kim, 2015 에서는 3, 4, 5 - gram 의 CNN filter 를 각각 100 개씩, 총 300 개의 filter 를 거친 뒤, dropout 과 fully connected layer 를 거쳐 softmax 로 classification 을 하였습니다. 우리는 한국어 데이터를 적용할 것이고, bigram 도 중요한 feature 이기 때문에 2, 3, 4 - gram 을 이용하는 CNN filter 를 만듭니다.\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(2, embedding_dim))\n",
    "    self.conv2 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, embedding_dim))\n",
    "    self.conv3 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(4, embedding_dim))\n",
    "\n",
    "Dropout layer 는 dropout_ratio 만 입력하면 됩니다. \n",
    "\n",
    "    self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "Fully connected layer 에 입력되는 값은 세 종류의 필터 각각 100 개씩, 총 300 개의 필터가 적용된 값입니다. (3 * num_filters, num_classes) 의 weight 를 지니는 fully connected layer 를 이용합니다.\n",
    "\n",
    "    self.fc1 = nn.Linear(3 * num_filters, num_classes)\n",
    "\n",
    "### forward 함수 구현\n",
    "\n",
    "우리는 세 종류의 CNN filter 를 각각 self.conv1, self.conv2, self.conv3 으로 만들었습니다. forward 함수에 입력된 x 가 각각의 convolution layer 를 거치면 각각의 output 값이 만들어집니다. 이 값을 concatenation 하여 fully connected layer 에 입력하는 input 으로 만들 것입니다.\n",
    "\n",
    "일단 입력된 단어열에 Embedding lookup 을 한 뒤, resize 를 합니다. unsqueese 를 하는 이유는 앞서 말한 바와 같이 torch.nn.Embedding 에 적용된 값은 channel 의 개수가 지정되지 않기 때문입니다. unsqueeze(1) 을 통하여 out 의 format 을 (bath, sent_len, embed_dim) 에서 (batch, channel_input, sent_len, embed_dim) 으로 변환합니다.\n",
    "\n",
    "    out = self.embed(x) # (batch, sent_len, embed_dim)\n",
    "    out = out.unsqueeze(1) # (batch, channel_input, sent_len, embed_dim)\n",
    "\n",
    "Embedding lookup 을 통하여 만들어진 sentence image, out 을 세 종류의 CNN filter 에 적용합니다. 이 값을 list 에 모두 저장합니다.\n",
    "\n",
    "    out = [F.relu(self.conv1(out)).squeeze(3),\n",
    "           F.relu(self.conv2(out)).squeeze(3),\n",
    "           F.relu(self.conv3(out)).squeeze(3)]\n",
    "\n",
    "각각의 CNN filter 가 적용된 값에 max pooling 을 적용합니다. 이 과정에서 squeeze, unsqueeze 를 왜 하는지 햇갈리시다면, 바로 위 chapter, applying CNN and pooling 을 다시 보시기 바랍니다.\n",
    "\n",
    "    out = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in out]\n",
    "\n",
    "현재 out 의 형태는 list of torch.Tensor 입니다. 이를 하나의 tensor 로 concatenation 합니다.\n",
    "\n",
    "    out = torch.cat(out, 1)\n",
    "\n",
    "이 값을 dropout 을 거치고, fully connected layer 에 넣습니다.\n",
    "\n",
    "    out = self.dropout(out)\n",
    "    logit = self.fc1(out) # (batch, target_size)\n",
    "\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, num_words, num_filters,\n",
    "                 num_classes, pretrained_wordvec, dropout_ratio=0.5):\n",
    "\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(num_words, embedding_dim)\n",
    "\n",
    "        # check word embedding vector shape\n",
    "        n, m = pretrained_wordvec.shape\n",
    "        assert n == num_words and m == embedding_dim\n",
    "\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(pretrained_wordvec))\n",
    "\n",
    "        # in_channels, out_channels, \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(2, embedding_dim), bias=False)\n",
    "        self.conv2 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(3, embedding_dim), bias=False)\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(4, embedding_dim), bias=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        # three type convolution. each conv. has num_filters\n",
    "        self.fc1 = nn.Linear(3 * num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: sentence image\n",
    "                torch.LongTensor\"\"\"\n",
    "\n",
    "        out = self.embed(x) # (batch, sent_len, embed_dim)\n",
    "        out = out.unsqueeze(1) # (batch, channel_input, sent_len, embed_dim)\n",
    "\n",
    "        # three convolution filter\n",
    "        out = [F.relu(self.conv1(out)).squeeze(3),\n",
    "               F.relu(self.conv2(out)).squeeze(3),\n",
    "               F.relu(self.conv3(out)).squeeze(3)]\n",
    "\n",
    "        # 1 - max pooling for each conv\n",
    "        out = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in out]\n",
    "\n",
    "        # concatenation\n",
    "        out = torch.cat(out, 1)\n",
    "\n",
    "        # dropout\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # fully connected neural network\n",
    "        logit = self.fc1(out) # (batch, target_size)\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 만듭니다. 그리고 print(model) 을 하면 직접 만든 모델의 구조가 출력됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(93235, 100)\n",
      "  (conv1): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1), bias=False)\n",
      "  (conv3): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1), bias=False)\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc1): Linear(in_features=300, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(\n",
    "    embedding_dim,\n",
    "    num_words,\n",
    "    num_filters,\n",
    "    num_classes,\n",
    "    wv\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 함수는 이전의 document classification 예시와 비슷합니다. 단, 우리는 직접 minibatch 를 구현할 겁니다. 그리고 static / non-static model 을 비교하기 위하여 word vector 가 변하는지 확인하는 부분을 추가하였습니다.\n",
    "\n",
    "네 가지 요소, model, loss function, optimizer, data 를 argument 로 받습니다. data 는 단어열 sents 와 각 문장의 sentiment 인 label 두 가지 입니다. 그 외에 epochs 횟수, mini batch size (batch_size) 도 추가로 입력받습니다.\n",
    "\n",
    "epochs 만큼 iteration 을 돕니다. 각 epoch 마다의 누적 loss 를 저장하기 위한 준비를 합니다.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0\n",
    "        # TODO\n",
    "\n",
    "mini batch 는 데이터의 일부로 loss 를 계산한 다음, 이를 반영하여 weight parameter 를 학습하는 것입니다. 데이터의 크기가 100 일 때, 한 번에 5 개의 데이터를 이용한다면 총 20 번의 mini batch 를 이용한 학습이 됩니다. 이는 다음처럼 구현합니다. begin (b), end (e) index 를 만들고, sents 와 label 에서 이에 해당하는 부분을 slicing 합니다.\n",
    "\n",
    "    for i in range(n_data // batch_size):\n",
    "\n",
    "        b = i * batch_size\n",
    "        e = min(n_data, (i+1) * batch_size)\n",
    "\n",
    "        x_batch = sents[b:e] # type : numpy.ndarray\n",
    "        y_batch = label[b:e] # type : numpy.ndarray\n",
    "\n",
    "이를 torch.Tensor 로 변환합니다.\n",
    "\n",
    "        x_batch = torch.LongTensor(x_batch)\n",
    "        y_batch = torch.LongTensor(y_batch)\n",
    "\n",
    "항상 optimizer 에 이전 step 에서 이용한 gradient 를 지운 뒤, forwarding, back-propagation 을 합니다.\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "prediction, loss 계산, 그리고 back propagation 을 수행합니다.\n",
    "\n",
    "        x_pred = model(x_batch)\n",
    "        loss = loss_func(x_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "loss 의 data 에는 loss 값이 저장되어 있습니다. 이는 torch.Tensor 이니 numpy() 를 이용하여 숫자로 변환하여 loss_sum 에 누적합니다.\n",
    "\n",
    "        loss_sum += loss.data.numpy()\n",
    "\n",
    "pretrained word embedding vector 가 변하는지 확인하기 위한 구문도 추가하였습니다. 0 번째 단어는 EMPTY 이기 때문에 1 번째 단어의 벡터의 첫 10 개의 값을 출력하는 함수를 더합니다.\n",
    "\n",
    "        print('### word2vec[1][:10]\\n{}'.format(wordvec[1, :10]))\n",
    "        print('### cnn embedding[1][:10]\\n{}'.format(model.embed.weight.data[1][:10].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, data_loader, epoch):\n",
    "\n",
    "    n_data = len(data_loader)\n",
    "    loss_sum = 0\n",
    "\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "\n",
    "        # clean gradient buffer zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # predict\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # compute loss & back-propagation\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # cumulate loss\n",
    "        loss_sum += loss.data.numpy()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            loss_tmp = loss_sum / (i+1)\n",
    "            print('\\repoch = {}, batch = {}, training loss = {}'.format(\n",
    "                epoch, i, '%.3f' % loss_tmp), end='', flush=True)\n",
    "\n",
    "    print('\\repoch = {}, training loss = {}{}'.format(\n",
    "        epoch, '%.3f' % (loss_sum / (i+1)), ' '*40), flush=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 model 과 train 함수를 모두 만들었으니 실제로 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## static\n",
    "\n",
    "Yoon Kim, 2015 에서의 static model 은 pretrained word vector 를 Embedding 의 값으로 이용하고, 더는 학습을 하지 않는 것입니다. \n",
    "\n",
    "먼저 model, loss function, optimizer 를 만듭니다.\n",
    "\n",
    "    model = TextCNN(embedding_dim, num_words, num_filters, num_classes, wordvec)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate\n",
    "    )\n",
    "\n",
    "학습이 되지 않게 만들려면 gradient 가 반영되지 않도록 설정하면 됩니다. PyTorch < 0.4 에서는 Variable 을 만들 때 이를 직접 설정할 수 있었습니다. 이는 torch.Tensor 에서도 가능합니다.\n",
    "\n",
    "    model.embed.weight.requires_grad = False\n",
    "\n",
    "앞서 만든 학습 함수를 이용하여 모델을 학습합니다.\n",
    "\n",
    "    train(model, loss_func, optimizer, sents, label, epochs=2, batch_size=512)\n",
    "\n",
    "실제로 static model 은 word vector 의 값이 변하지 않음을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, training loss = 0.451                                        \n",
      "epoch = 2, training loss = 0.431                                        \n",
      "epoch = 3, training loss = 0.424                                        \n",
      "epoch = 4, training loss = 0.421                                        \n",
      "epoch = 5, training loss = 0.418                                        \n",
      "\n",
      "epoch = 6, training loss = 0.416                                        \n",
      "epoch = 7, training loss = 0.414                                        \n",
      "epoch = 8, training loss = 0.412                                        \n",
      "epoch = 9, training loss = 0.411                                        \n",
      "epoch = 10, training loss = 0.410                                        \n",
      "\n",
      "epoch = 11, training loss = 0.409                                        \n",
      "epoch = 12, training loss = 0.408                                        \n",
      "epoch = 13, training loss = 0.408                                        \n",
      "epoch = 14, training loss = 0.407                                        \n",
      "epoch = 15, training loss = 0.406                                        \n",
      "\n",
      "epoch = 16, training loss = 0.405                                        \n",
      "epoch = 17, training loss = 0.405                                        \n",
      "epoch = 18, training loss = 0.405                                        \n",
      "epoch = 19, training loss = 0.404                                        \n",
      "epoch = 20, training loss = 0.403                                        \n",
      "\n",
      "epoch = 21, training loss = 0.403                                        \n",
      "epoch = 22, training loss = 0.402                                        \n",
      "epoch = 23, training loss = 0.402                                        \n",
      "epoch = 24, training loss = 0.402                                        \n",
      "epoch = 25, training loss = 0.401                                        \n",
      "\n",
      "epoch = 26, training loss = 0.401                                        \n",
      "epoch = 27, training loss = 0.401                                        \n",
      "epoch = 28, training loss = 0.400                                        \n",
      "epoch = 29, training loss = 0.400                                        \n",
      "epoch = 30, training loss = 0.400                                        \n",
      "\n",
      "epoch = 31, training loss = 0.400                                        \n",
      "epoch = 32, training loss = 0.399                                        \n",
      "epoch = 33, training loss = 0.399                                        \n",
      "epoch = 34, training loss = 0.399                                        \n",
      "epoch = 35, training loss = 0.398                                        \n",
      "\n",
      "epoch = 36, training loss = 0.399                                        \n",
      "epoch = 37, training loss = 0.398                                        \n",
      "epoch = 38, training loss = 0.398                                        \n",
      "epoch = 39, training loss = 0.398                                        \n",
      "epoch = 40, training loss = 0.398                                        \n",
      "\n",
      "epoch = 41, training loss = 0.397                                        \n",
      "epoch = 42, training loss = 0.397                                        \n",
      "epoch = 43, training loss = 0.397                                        \n",
      "epoch = 44, training loss = 0.397                                        \n",
      "epoch = 45, training loss = 0.396                                        \n",
      "\n",
      "epoch = 46, training loss = 0.396                                        \n",
      "epoch = 47, training loss = 0.397                                        \n",
      "epoch = 48, training loss = 0.396                                        \n",
      "epoch = 49, training loss = 0.396                                        \n",
      "epoch = 50, training loss = 0.396                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "# model = TextCNN(embedding_dim, num_words, num_filters, num_classes, wv)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.02\n",
    ")\n",
    "\n",
    "# do not update word embedding vector if static mode\n",
    "model.embed.weight.requires_grad = False\n",
    "\n",
    "for epoch in range(1, 50 + 1):\n",
    "    model = train(model, loss_func, optimizer, data_loader, epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, training loss = 0.396                                        \n",
      "epoch = 2, training loss = 0.396                                        \n",
      "epoch = 3, training loss = 0.395                                        \n",
      "epoch = 4, training loss = 0.395                                        \n",
      "epoch = 5, training loss = 0.395                                        \n",
      "\n",
      "epoch = 6, training loss = 0.395                                        \n",
      "epoch = 7, training loss = 0.395                                        \n",
      "epoch = 8, training loss = 0.395                                        \n",
      "epoch = 9, training loss = 0.395                                        \n",
      "epoch = 10, training loss = 0.395                                        \n",
      "\n",
      "epoch = 11, training loss = 0.394                                        \n",
      "epoch = 12, training loss = 0.394                                        \n",
      "epoch = 13, training loss = 0.394                                        \n",
      "epoch = 14, training loss = 0.394                                        \n",
      "epoch = 15, training loss = 0.394                                        \n",
      "\n",
      "epoch = 16, training loss = 0.394                                        \n",
      "epoch = 17, training loss = 0.394                                        \n",
      "epoch = 18, training loss = 0.394                                        \n",
      "epoch = 19, training loss = 0.394                                        \n",
      "epoch = 20, training loss = 0.393                                        \n",
      "\n",
      "epoch = 21, training loss = 0.393                                        \n",
      "epoch = 22, training loss = 0.393                                        \n",
      "epoch = 23, training loss = 0.393                                        \n",
      "epoch = 24, training loss = 0.393                                        \n",
      "epoch = 25, training loss = 0.393                                        \n",
      "\n",
      "epoch = 26, training loss = 0.393                                        \n",
      "epoch = 27, training loss = 0.393                                        \n",
      "epoch = 28, training loss = 0.393                                        \n",
      "epoch = 29, training loss = 0.393                                        \n",
      "epoch = 30, training loss = 0.393                                        \n",
      "\n",
      "epoch = 31, training loss = 0.393                                        \n",
      "epoch = 32, training loss = 0.392                                        \n",
      "epoch = 33, training loss = 0.392                                        \n",
      "epoch = 34, training loss = 0.392                                        \n",
      "epoch = 35, training loss = 0.392                                        \n",
      "\n",
      "epoch = 36, training loss = 0.392                                        \n",
      "epoch = 37, training loss = 0.392                                        \n",
      "epoch = 38, training loss = 0.392                                        \n",
      "epoch = 39, batch = 14930, training loss = 0.391"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0c9e4816103d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-8f06b61f39f2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_func, optimizer, data_loader, epoch)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# compute loss & back-propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100 + 1):\n",
    "    model = train(model, loss_func, optimizer, data_loader, epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance\n",
    "\n",
    "학습 성능을 확인합니다. 모델링에 집중하기 위하여 학습 / 테스트 데이터를 나누는 것은 하지 않았습니다. 이번에 우리가 측정하는 것은 training accuracy 입니다.\n",
    "\n",
    "학습 데이터 전체를 torch.LongTensor 로 바꾼 뒤, batch prediction 을 합니다. torch.max 를 이용하여 probability 와 predicted label 을 얻습니다. torch.max 는 dim 기준 (dim=1 이기 때문에 column) max 값과 그 값에 해당하는 index 를 return 합니다.\n",
    "\n",
    "    y_pred = model(torch.LongTensor(sents))\n",
    "    score, predicted = torch.max(y_pred.data, dim=1)\n",
    "\n",
    "numpy.where 을 이용하여 같은 label 을 지니는 rows 의 개수를 확인합니다. 이를 통하여 학습 정확도를 측정합니다.\n",
    "\n",
    "    n_correct = np.where(label == predicted.numpy())[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 batch was done\n",
      "accuracy = 0.84815625\n"
     ]
    }
   ],
   "source": [
    "def accuracy_test(model, data_loader, first_batch=1000):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        for i, (X, y) in enumerate(data_loader):\n",
    "            if i == first_batch:\n",
    "                break\n",
    "            y_pred = model(X)\n",
    "            score, predicted = torch.max(y_pred.data, dim=1)\n",
    "            n_correct += (predicted == y).sum().numpy()\n",
    "            print('\\r%d batch ...' % i, end='')\n",
    "        print('\\r%d batch was done' % i)\n",
    "\n",
    "    accuracy = n_correct / (i * batch_size)\n",
    "    print('accuracy = {}'.format(accuracy))\n",
    "\n",
    "accuracy_test(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './textcnn_params.pt'\n",
    "# torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
