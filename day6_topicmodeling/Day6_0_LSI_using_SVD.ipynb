{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미리 만들어둔 document - term matrix 를 이용하여 LSI 를 학습합니다. 이를 위해서 SVD 를 직접 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../../data/corpus_10days/models/params_keywords', 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "x = params['x']\n",
    "vocab2idx = params['word2index']\n",
    "idx2vocab = params['index2word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서마다 단어의 개수가 다르기 때문에 L2 normalization 을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x_ = normalize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TruncatedSVD 를 이용하면 n_components 차원으로 문서와 단어의 공간을 바꿀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "y = svd.fit_transform(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "document - term matrix 는 (30091, 9774) 의 행렬이었습니다. 9,774 개의 단어로 이뤄진 문서의 공간이 100 차원의 공간으로 바뀌었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30091, 9774) (30091, 100)\n"
     ]
    }
   ],
   "source": [
    "print(x_.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어에 대한 100 차원의 벡터는 components_ 에 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9774)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 이용하여 topically similar terms 와 topically similar docs 를 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def most_similar_terms(term, topn=10):\n",
    "\n",
    "    # encode term as index\n",
    "    idx = vocab2idx.get(term, -1)\n",
    "    if idx < 0:\n",
    "        return []\n",
    "    \n",
    "    # prepare query term vector\n",
    "    query_vec = svd.components_[:,idx].reshape(1,-1)\n",
    "\n",
    "    # compute cosine - distance\n",
    "    dist = pairwise_distances(\n",
    "        # transpose word vectors : (100, 9774) -> (9774, 100)\n",
    "        svd.components_.transpose(),\n",
    "        query_vec,\n",
    "        metric='cosine'\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    # find most closest terms\n",
    "    similar_idx = dist.argsort()[:topn]\n",
    "    \n",
    "    # get their distance\n",
    "    similar_dist = dist[similar_idx]\n",
    "    \n",
    "    # format : [(term, distance), ... ]\n",
    "    similar_terms = [(idx, d) for idx, d in zip(similar_idx, similar_dist)]\n",
    "    \n",
    "    # decode term index to vocabulary\n",
    "    similar_terms = [(idx2vocab[idx], d) for idx, d in similar_terms]\n",
    "\n",
    "    # return\n",
    "    return similar_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'아이오아이'의 topically similar terms 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이오아이', 1.1102230246251565e-16),\n",
       " ('신용재', 0.04015749988006123),\n",
       " ('엠카운트다운', 0.04376174748669781),\n",
       " ('오블리스', 0.0456031178529811),\n",
       " ('빅브레인', 0.0467705423425252),\n",
       " ('너무너무너무', 0.05191660254815156),\n",
       " ('세븐', 0.06866961383970227),\n",
       " ('갓세븐', 0.07091395215096752),\n",
       " ('산들', 0.11148465700268906),\n",
       " ('중독성', 0.11373631637330073)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_terms('아이오아이')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'오바마'의 topically similar terms 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('오바마', 0.0),\n",
       " ('버락', 0.02842665009085288),\n",
       " ('백악관', 0.10196960176734082),\n",
       " ('주지사', 0.1818647366158357),\n",
       " ('꼭두각시', 0.19674068147232604),\n",
       " ('이민자', 0.21531647556387057),\n",
       " ('클린턴', 0.2251726272441089),\n",
       " ('장벽', 0.2273930054140233),\n",
       " ('공화당', 0.23119685454084837),\n",
       " ('푸틴', 0.23313240797754864)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_terms('오바마')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어와 문서의 100 차원의 벡터를 학습하였으니, 이를 이용하여 해당 단어와 topically relavant 한 문서들을 검색할 수 있습니다.\n",
    "\n",
    "각 문서에 대해 most frequent terms 를 확인하기 위하여 get_bow 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_docs_from_term(term, topn=10):\n",
    "\n",
    "    # encode term as index\n",
    "    idx = vocab2idx.get(term, -1)\n",
    "    if idx < 0:\n",
    "        return []\n",
    "\n",
    "    # prepare query term vector\n",
    "    query_vec = svd.components_[:,idx].reshape(1,-1)\n",
    "\n",
    "    # compute distance between query term vector and document vectors\n",
    "    dist = pairwise_distances(\n",
    "        y,\n",
    "        query_vec,\n",
    "        metric='cosine'\n",
    "    ).reshape(-1)\n",
    "    \n",
    "    # find similar document indices\n",
    "    similar_doc_idx = dist.argsort()[:topn]\n",
    "\n",
    "    # return\n",
    "    return similar_doc_idx\n",
    "\n",
    "def get_bow(doc_idx, topn=10):\n",
    "\n",
    "    # get term frequency submatrix\n",
    "    x_sub = x[doc_idx,:]\n",
    "\n",
    "    # get term indices and their frequencies\n",
    "    terms = x_sub.nonzero()[1]\n",
    "    freqs = x_sub.data\n",
    "    \n",
    "    # format : [(term, frequency), ... ]\n",
    "    bow = [(term, freq) for term, freq in zip(terms, freqs)]\n",
    "    \n",
    "    # sort by frequency in decreasing order\n",
    "    bow = sorted(bow, key=lambda x:-x[1])[:topn]\n",
    "    \n",
    "    # decode term index to vocabulary\n",
    "    bow = [(idx2vocab[term], freq) for term, freq in bow]\n",
    "    \n",
    "    # return\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'오바마'와 관련된 문서들입니다. 2016-10 에는 미국 대선이 이뤄지던 기간입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc#=9615 : [('오바마', 11), ('트럼프', 11), ('대통령', 10), ('미국', 5), ('초대', 4), ('토론', 4), ('대변', 3), ('지지', 3), ('케냐', 3), ('힐러리', 3)]\n",
      "doc#=9471 : [('오바마', 13), ('대통령', 12), ('트럼프', 11), ('미국', 6), ('초대', 4), ('대변', 3), ('지지', 3), ('케냐', 3), ('토론', 3), ('부인', 2)]\n",
      "doc#=14951 : [('트럼프', 10), ('대통령', 7), ('클린턴', 7), ('후보', 7), ('공화당', 4), ('결과', 3), ('꼭두각시', 3), ('대선', 3), ('비방', 3), ('기자', 2)]\n",
      "doc#=7256 : [('트럼프', 25), ('힐러리', 17), ('대통령', 7), ('토론', 7), ('푸틴', 6), ('미국', 5), ('여자', 5), ('끔찍', 4), ('러시아', 4), ('꼭두각시', 3)]\n",
      "doc#=11929 : [('대통령', 7), ('오바마', 7), ('트럼프', 7), ('선거', 6), ('주장', 6), ('조작', 5), ('대선', 4), ('이라고', 4), ('클린턴', 4), ('후보', 4)]\n",
      "doc#=11441 : [('공화당', 20), ('대통령', 7), ('로비', 6), ('선거', 6), ('후보', 6), ('것이다', 5), ('미국', 5), ('조직', 4), ('트럼프', 4), ('권력', 3)]\n",
      "doc#=27797 : [('트럼프', 31), ('클린턴', 20), ('대통령', 12), ('미국', 9), ('토론', 9), ('꼭두각시', 6), ('여성', 6), ('후보', 6), ('19일', 5), ('뉴스1', 5)]\n",
      "doc#=30018 : [('토론', 12), ('트럼프', 9), ('후보', 7), ('클린턴', 6), ('3차', 5), ('대선', 4), ('대통령', 4), ('미국', 4), ('오바마', 4), ('토론장', 4)]\n",
      "doc#=9619 : [('트럼프', 17), ('여론조사', 5), ('힐러리', 5), ('노조', 4), ('대통령', 3), ('미국', 3), ('시위', 3), ('이같', 3), ('주장', 3), ('토론회', 3)]\n",
      "doc#=9479 : [('트럼프', 18), ('여론조사', 5), ('힐러리', 5), ('노조', 4), ('대통령', 3), ('미국', 3), ('시위', 3), ('이같', 3), ('이라고', 3), ('주장', 3)]\n"
     ]
    }
   ],
   "source": [
    "for doc_idx in most_similar_docs_from_term('오바마'):\n",
    "    bow = get_bow(doc_idx)\n",
    "    print('doc#={} : {}'.format(doc_idx, bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
